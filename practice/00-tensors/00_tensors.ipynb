{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 00. Tensors\n",
        "\n",
        "This Jupyter Notebook is authored by [awdev](https://github.com/AWeirdScratcher), which contains summarizations and partial contents from [learnpytorch.io](https://learnpytorch.io). To learn more about this notebook, see [üêô AWeirdScratcher/models](https://github.com/AWeirdScratcher/models) to find out more.\n",
        "\n",
        "Note: Click on the first icon on the left navigation to explore the outlines of this notebook.\n",
        "\n",
        "<br />\n",
        "\n",
        "[![Learn PyTorch](https://img.shields.io/badge/Learn-%23EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white)](https://www.learnpytorch.io/00_pytorch_fundamentals/)\n",
        "[![Ramptix](https://img.shields.io/badge/%E2%AC%9C%20%E2%94%82%20Ramptix-%23202020?style=for-the-badge)](https://github.com/ramptix)"
      ],
      "metadata": {
        "id": "PX4pnAduQgsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "1hOibzvZSufE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basics\n",
        "Tensors are one of the core building blocks of Pytorch, and there are many types of them, including:\n",
        "\n",
        "- Scalar\n",
        "- Vector\n",
        "- Matrix\n",
        "- Tensor\n",
        "\n",
        "Let's go through them one by one.\n",
        "\n",
        "<br /><hr /><br />\n",
        "\n",
        "Scalar: A single number, and in \"tensor-speak,\" it's a zero dimension tensor.\n",
        "\n",
        "- Dimensions: `0`\n",
        "- Example usage: `a` (lower)\n",
        "\n",
        "An example of a scalar would be like:\n",
        "\n",
        "```python\n",
        "a = torch.tensor(69)\n",
        "```"
      ],
      "metadata": {
        "id": "5HzYcRAiPupf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example scalar\n",
        "scalar = torch.tensor(4.2)\n",
        "\n",
        "print(scalar)\n",
        "print(\"shape:\", scalar.shape)\n",
        "print(\"dimensions:\", scalar.ndim)"
      ],
      "metadata": {
        "id": "yQ_FKbUjSolx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c4f47e4-1e2f-4714-f10f-f464d59b714e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.2000)\n",
            "shape: torch.Size([])\n",
            "dimensions: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vector**: A single-dimensional tensor that can contain many numbers.\n",
        "- Dimensions: `1`\n",
        "- Example usage: `y` (lower)\n",
        "\n",
        "An example of a vector would be like:\n",
        "\n",
        "```python\n",
        "y = torch.tensor([1, 2, 3, 4, ...])\n",
        "```\n",
        "\n",
        "There's only one dimension, sort of like a 1d-line."
      ],
      "metadata": {
        "id": "xgTVowe_VX_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector = torch.tensor([6, 9, 4, 2, 0])\n",
        "\n",
        "print(vector)\n",
        "print(\"shape:\", vector.shape)\n",
        "print(\"dimensions:\", vector.ndim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kss4k7vWMh0q",
        "outputId": "76a6fff2-8b88-445a-f148-1a4ad0be97ce"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([6, 9, 4, 2, 0])\n",
            "shape: torch.Size([5])\n",
            "dimensions: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Counting Dimensions**\n",
        ">\n",
        "> To count the number of dimensions, check how many open square brackets (`[`) there are at the beginning of the tensor's `repr`. For example, a tensor like-\n",
        "> ```python\n",
        "> tensor([1, 2, 3])\n",
        "> ```\n",
        "> ...would have 1 dimension, because there are two open square brackets.\n",
        ">\n",
        "> (Summarization)"
      ],
      "metadata": {
        "id": "QicoeLbwNShE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Exercise { display-mode: \"form\"}\n",
        "# @markdown How many dimensions:\n",
        "# @markdown ```python\n",
        "# @markdown tensor([[1, 9], [8, 9]])\n",
        "# @markdown ```\n",
        "answer = -1 # @param { type: \"number\" }"
      ],
      "metadata": {
        "id": "IJncnNeRMk3w"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Exercise: Check Answer { display-mode: \"form\" }\n",
        "# @markdown Run this cell to check your answer.\n",
        "if answer == -1:\n",
        "  print(\"Please enter your answer.\")\n",
        "\n",
        "print(\"Correct!\" if answer == 2 else \"Incorrect\")"
      ],
      "metadata": {
        "id": "X13fZznvP5vi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22fbdf85-633d-4733-8ced-e88504c09969"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter your answer.\n",
            "Incorrect\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Matrix**: Has two dimensions (can contain \"sub-lists\" in the concept of vanilla Python).\n",
        "\n",
        "- Dimensions: `2`\n",
        "- Example usage: `Q` (upper)\n",
        "\n",
        "An example of a matrix would be like:\n",
        "\n",
        "```python\n",
        "Q = torch.tensor([\n",
        "  [1, 9, 8, 9],\n",
        "  [0, 6, 0, 4]\n",
        "])\n",
        "```"
      ],
      "metadata": {
        "id": "ZsnjNPJrTgx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX = torch.tensor([\n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "])\n",
        "\n",
        "MATRIX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-pCRMuDUNuW",
        "outputId": "320757ba-1aca-43a0-cdeb-6cc4a67b9061"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check its shape & number of dimensions\n",
        "MATRIX.shape, MATRIX.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYdy8PZBUZGC",
        "outputId": "4981da71-5c66-4918-f6d3-c08ec6d89163"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 3]), 2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The shape implies that the first dimension has `2` elements, and the second one has `3` elements.\n",
        "\n",
        "Alternatively, you can think of the shape `torch.Size([2, 3])` as a 2x3 grid (`2` in height, `3` in width)."
      ],
      "metadata": {
        "id": "fCTIZ7t9UpNg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensor**: An $n$-dimensional array of numbers.\n",
        "\n",
        "- Dimensions: $n$\n",
        "- Example usage: `X` (upper)\n",
        "\n",
        "An example of an $n$-dimensional tensor would be:\n",
        "\n",
        "```python\n",
        "X = torch.tensor([\n",
        "  [\n",
        "    [0, 1, 2],\n",
        "    [3, 4, 5]\n",
        "  ]\n",
        "])\n",
        "```"
      ],
      "metadata": {
        "id": "7_bY0duEU4Ko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR = torch.tensor([\n",
        "    [\n",
        "        [1, 9, 8, 9],\n",
        "        [0, 6, 0, 4]\n",
        "    ]\n",
        "])\n",
        "\n",
        "TENSOR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w12EScUg8efT",
        "outputId": "b02ff1f2-16c6-426f-d5ac-91af0c96a5ee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 9, 8, 9],\n",
              "         [0, 6, 0, 4]]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR.shape, TENSOR.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbL5rQt79goW",
        "outputId": "22ae321a-5da8-4c17-e768-e72b75cd5860"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 2, 4]), 3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This implies that there are three dimensions."
      ],
      "metadata": {
        "id": "3CdJxD4N9mkb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensors on GPU\n",
        "\n",
        "You can store tensors on GPU as well."
      ],
      "metadata": {
        "id": "2vyUCQZ5_yKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if device != 'cuda':\n",
        "  print(\"You don't have CUDA.\")\n",
        "else:\n",
        "  # put a tensor on cuda gpu\n",
        "  a = torch.tensor([1, 2, 3], device=\"cuda\")\n",
        "  print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6mCloZd_2OA",
        "outputId": "24202322-22b1-45b9-b1a5-3fe8e3b60e2a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you have an existing tensor to put on CUDA, use `tensor.to(device)`."
      ],
      "metadata": {
        "id": "Qw4k_SsrARJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if device != 'cuda':\n",
        "  print(\"You don't have CUDA.\")\n",
        "else:\n",
        "  a = torch.tensor([1, 2, 3])\n",
        "  a = a.to(\"cuda\")\n",
        "  print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JktEU13APMu",
        "outputId": "5bc69ea6-4ddb-4b6d-e415-3ecd04ba7765"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Or, convert to CPU\n",
        "a = torch.tensor([1, 2, 3], device='cpu')\n",
        "# a.to('cpu')\n",
        "\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-9o5kjpAjHU",
        "outputId": "552bee41-e778-41c9-f7f9-3290dedc8a41"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPU Device"
      ],
      "metadata": {
        "id": "aOphf7L3zINs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xB3oXMjzKln",
        "outputId": "01cc79f8-b92d-43e9-86e3-abfde342a396"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jan 29 10:41:33 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0              26W /  70W |    105MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Tensors\n",
        "\n",
        "A machine learning model often starts out with large random tensors of numbers and adjusts these them as it works through data to better represent it.\n",
        "\n",
        "In essence:\n",
        "\n",
        "```markdown\n",
        "1. Start with random numbers\n",
        "2. Look at data\n",
        "3. Update random numbers\n",
        "4. Start with random numbers\n",
        "5. Look at data\n",
        "...continue\n",
        "```\n",
        "\n",
        "<br />\n",
        "\n",
        "<hr />\n",
        "\n",
        "<br />\n",
        "\n",
        "To create a random tensor in Pytorch, use the `torch.rand(size)` function, where `size` is the shape of the tensor."
      ],
      "metadata": {
        "id": "wmgprLR--GQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random tensor\n",
        "tensor_a = torch.rand(3, 5) # create a 3x5\n",
        "tensor_a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGK93tWg-kxD",
        "outputId": "606a3908-dab2-444d-ec85-3d468790b052"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1796, 0.7897, 0.8344, 0.9858, 0.3416],\n",
              "        [0.6639, 0.2644, 0.1054, 0.4837, 0.2422],\n",
              "        [0.7584, 0.2750, 0.1260, 0.2989, 0.8472]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There's also `torch.randint(low=0, high, size)` for creating tensors filled with random integers generated uniformly between `low` and `high`."
      ],
      "metadata": {
        "id": "zxMYbg-28hpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate integers from one to five in a vector\n",
        "torch.randint(1, 5, size=(10,))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiMe9nQt86Fu",
        "outputId": "60261d72-019f-451b-b828-0ecf62102174"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4, 1, 3, 4, 3, 1, 2, 2, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manual Seed\n",
        "\n",
        "To make the result more reproducible, use `torch.manual_seed(seed)`.\n",
        "\n",
        "> <sub><b><a href=\"https://pytorch.org/docs/stable/generated/torch.manual_seed.html#torch-manual-seed\" target=\"_blank\">TORCH.MANUAL_SEED</a></b></sub>\n",
        ">\n",
        "> **`torch.manual_seed(seed: int)`** [\\[SOURCE\\]](https://pytorch.org/docs/stable/_modules/torch/random.html#manual_seed)\n",
        ">\n",
        "> Sets the seed for generating random numbers.\n",
        "> - seed (<a href=\"https://docs.python.org/3/library/functions.html#int\"><i>int</i></a>) - The desired seed."
      ],
      "metadata": {
        "id": "R5U7Epl9-qL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncVZ3aD1-ywk",
        "outputId": "2556b602-e6ff-4666-feb7-5733f9889f34"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fe03878d5b0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now create a random tensor and see if it's:\n",
        "\n",
        "```python\n",
        "tensor([[0.8823, 0.9150, 0.3829],\n",
        "        [0.9593, 0.3904, 0.6009]])\n",
        "```\n",
        "\n",
        "...at the first time."
      ],
      "metadata": {
        "id": "g5t7vojAA4S-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor = torch.rand(2, 3)\n",
        "random_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xcb-ARP0BAMq",
        "outputId": "9bd32a20-b5b5-4c08-ba52-ac7df6877a43"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8823, 0.9150, 0.3829],\n",
              "        [0.9593, 0.3904, 0.6009]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manual Seed for CUDA\n",
        "\n",
        "To set a seed for CUDA (GPU), use `torch.cuda.manual_seed(seed)`."
      ],
      "metadata": {
        "id": "q-zTfqruFxtj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if device == 'cuda':\n",
        "  torch.cuda.manual_seed(42)\n",
        "  cuda_random_tensor = torch.rand(2, 3, device=device)\n",
        "  print(cuda_random_tensor)\n",
        "else:\n",
        "  print(\"cuda not available, got gpu.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jz9j_jTDF-f4",
        "outputId": "cee84d2a-4672-4a12-803a-be4458641df1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6130, 0.0101, 0.3984],\n",
            "        [0.0403, 0.1563, 0.4825]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zeros & Ones\n",
        "\n",
        "Create an $n$-dimensional tensor filled with zeros or ones with a given `size` (desired output shape) using `torch.zeros` or `torch.ones`."
      ],
      "metadata": {
        "id": "PALcsK9xGlej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zeros = torch.zeros(3, 4)\n",
        "ones = torch.ones(3, 4)\n",
        "\n",
        "print(zeros)\n",
        "print(ones)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTbP3FbhH4c1",
        "outputId": "cab2d496-7707-491c-a22b-73693b995ef6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]])\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zeros-like & Ones-like\n",
        "\n",
        "Sometimes you might want to create a tensor filled with zeros or ones based on the shape of another tensor.\n",
        "\n",
        "You can achieve this by using `torch.zeros_like(input)` or `torch.ones_like(input)`."
      ],
      "metadata": {
        "id": "kEjd0XcDIERM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random tensor (5x5)\n",
        "x = torch.rand(5, 5)\n",
        "\n",
        "zeros = torch.zeros_like(x)\n",
        "ones = torch.ones_like(x)\n",
        "\n",
        "print(zeros)\n",
        "print(ones)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOixpnE2IQjN",
        "outputId": "35a20bf6-6180-41db-fee8-347775793966"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]])\n",
            "tensor([[1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Equivalent (using `x.shape`)\n",
        "shape = x.shape\n",
        "\n",
        "zeros = torch.zeros(shape)\n",
        "ones = torch.ones(shape)\n",
        "\n",
        "print(zeros)\n",
        "print(ones)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQSW0DTuIaUV",
        "outputId": "875f51da-8f61-484b-93ba-bd890a00e452"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]])\n",
            "tensor([[1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filling Tensors\n",
        "\n",
        "Sometimes you might want to fill the whole tensor with a number.\n",
        "\n",
        "You can achieve this using `torch.fill()` or `x.fill_()`"
      ],
      "metadata": {
        "id": "xBrYUbWGZZRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random matrix (3x3)\n",
        "x = torch.rand(3, 3)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_ScOFXaZctm",
        "outputId": "f9964e01-c02e-4c23-d19c-576ce1c08659"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0753, 0.8860, 0.5832],\n",
              "        [0.3376, 0.8090, 0.5779],\n",
              "        [0.9040, 0.5547, 0.3423]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill the tensor with 7\n",
        "torch.fill(x, 7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQCAqAlmaBgH",
        "outputId": "600cb22e-bc80-4502-a568-ecb5d9ed168f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[7., 7., 7.],\n",
              "        [7., 7., 7.],\n",
              "        [7., 7., 7.]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Or use tensor.fill_()\n",
        "x.fill_(7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7PbOihtagZK",
        "outputId": "9f36f723-13a9-4334-c315-9d1f9edc8352"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[7., 7., 7.],\n",
              "        [7., 7., 7.],\n",
              "        [7., 7., 7.]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also fill the tensor with zeros in one move!"
      ],
      "metadata": {
        "id": "kOY-1kJgarTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3AatJXLawLA",
        "outputId": "c0f2a323-2960-488b-ea56-92f21af467ea"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Warning**\n",
        ">\n",
        "> Using `tensor.fill_()` or `tensor.zero_()` will *directly* affect the original tensor. If you don't want that to happen, just use `torch.fill()` or [`torch.zeros_like()`](#scrollTo=Zeros_like_Ones_like)."
      ],
      "metadata": {
        "id": "lsLQZsJ_eN2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(2, 3)"
      ],
      "metadata": {
        "id": "s2q_gbf5fFV0"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.fill()\n",
        "print(\"torch.fill()\")\n",
        "print(torch.fill(tensor, 7))\n",
        "print(\"tensor:\")\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9Jdws8Sel6q",
        "outputId": "d9bae9ab-a12a-4d31-9e9b-259215f69738"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.fill()\n",
            "tensor([[7., 7., 7.],\n",
            "        [7., 7., 7.]])\n",
            "tensor:\n",
            "tensor([[0.6343, 0.3644, 0.7104],\n",
            "        [0.9464, 0.7890, 0.2814]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.zeros_like()\n",
        "print(\"torch.zeros_like()\")\n",
        "print(torch.zeros_like(tensor))\n",
        "print(\"tensor:\")\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBp3XGaJeynD",
        "outputId": "7cd1b088-e8f7-41ce-9ebe-8a55495f96fa"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.zeros_like()\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor:\n",
            "tensor([[0.6343, 0.3644, 0.7104],\n",
            "        [0.9464, 0.7890, 0.2814]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Range\n",
        "\n",
        "Use `torch.arange(start, end, step)` to create a tensor of a range of numbers like 0 to 100.\n",
        "\n",
        "> <sub><b><a href=\"https://pytorch.org/docs/stable/generated/torch.arange.html#torch-arange\" target=\"_blank\">TORCH.ARANGE</a></b></sub>\n",
        ">\n",
        "> `torch.arange(start=0, end, step=1, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)`\n",
        ">\n",
        "> Returns a 1-D tensor of size $\\lceil\\frac{end-start}{step}\\rceil$ with values from the interval `start, end` taken with common difference step beginning from start.\n",
        "> - start (Number) - the starting value for the set of points. Default: `0`.\n",
        "> - end (Number) - the ending value for the set of points\n",
        "> - step (Number) - the gap between each pair of adjacent points. Default: `1`."
      ],
      "metadata": {
        "id": "KLvjaxxFIqGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "range_ = torch.arange(start=0, end=20, step=1)\n",
        "range_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Lp_EPchKn3y",
        "outputId": "5aa9cc4a-83fe-491e-cf3c-2c860b98c577"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "        18, 19])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try changing the step\n",
        "range_ = torch.arange(start=0, end=20, step=5)\n",
        "range_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuZ-BsYzKw6b",
        "outputId": "cd33c03a-5d45-43ab-92e4-4c0d32a049ea"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  5, 10, 15])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Datatypes\n",
        "\n",
        "The most common datatype in Pytorch (which is the default) is `torch.float32` (also known as `torch.float`). This is also referred to as \"32-bit floating point.\"\n",
        "\n",
        "Additionally, there's also a 16-bit floating point (`torch.float16` aka. `torch.half`) and a 64-bit floating point (`torch.float64` aka. `torch.double`).\n",
        "\n",
        "The reason for using those different datatypes is to do with **precision** in computing, and \"precision\" is the amount of detail used to describe a number. The higher the value is, the more detail (and hence data) is used to describe a number. However, a higher precision value might lead to a slower performance; a lower precision value is indeed fast but might sacrifice the model's accuracy.\n",
        "\n",
        "Let's create a tensor with a specific datatype (`float64`)."
      ],
      "metadata": {
        "id": "l_BlIZF3K8v1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# float64 datatype\n",
        "x = torch.rand(3, 3, dtype=torch.float64)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_98PtG9aLLw6",
        "outputId": "c46160a2-dda1-453a-e52f-48e4d5f30cdc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3091, 0.0313, 0.0404],\n",
              "        [0.9319, 0.1521, 0.2650],\n",
              "        [0.1304, 0.2519, 0.2334]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check datatype of a tensor\n",
        "x.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74bAMNseLQlR",
        "outputId": "089c97ce-bc1c-456c-8965-db161a255eb5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float64"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To change the datatype of a tensor, use `tensor.type()`."
      ],
      "metadata": {
        "id": "VsekneMFUxzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert a tensor to a specific datatype (say, float16)\n",
        "x.type(torch.half)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rI-VaQ5OLnY6",
        "outputId": "35a7cde1-a703-40f9-bd61-82103d825b98"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3091, 0.0313, 0.0404],\n",
              "        [0.9321, 0.1521, 0.2651],\n",
              "        [0.1305, 0.2520, 0.2334]], dtype=torch.float16)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There's also one datatype I find interesting ‚Äî `torch.bool`.\n",
        "\n",
        "It acts like a boolean in Python!"
      ],
      "metadata": {
        "id": "yMqQkBUE7PUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 5x5 tensor filled with zeros and ones randomly\n",
        "x = torch.randint(0, 2, size=(5, 5))\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jl9VNOkv7d40",
        "outputId": "39c33706-935d-4848-dc4b-334869f600fb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 1, 0, 1],\n",
              "        [1, 1, 1, 0, 1],\n",
              "        [0, 1, 1, 1, 0],\n",
              "        [1, 0, 1, 0, 1],\n",
              "        [0, 0, 1, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert it into a torch.bool type\n",
        "# Both x.bool() and x.to(torch.bool) works, it's just a matter of time\n",
        "%%time\n",
        "x.bool()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UW8FdBBQ9aJq",
        "outputId": "5d51b23b-e85b-4a87-c48f-b8180b5ec4a2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 44 ¬µs, sys: 10 ¬µs, total: 54 ¬µs\n",
            "Wall time: 58.9 ¬µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False,  True,  True, False,  True],\n",
              "        [ True,  True,  True, False,  True],\n",
              "        [False,  True,  True,  True, False],\n",
              "        [ True, False,  True, False,  True],\n",
              "        [False, False,  True, False,  True]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "x.to(torch.bool)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5CBGSOc9ycw",
        "outputId": "1202f1a4-58c3-4f51-84df-6fd63398891d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 103 ¬µs, sys: 22 ¬µs, total: 125 ¬µs\n",
            "Wall time: 131 ¬µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False,  True,  True, False,  True],\n",
              "        [ True,  True,  True, False,  True],\n",
              "        [False,  True,  True,  True, False],\n",
              "        [ True, False,  True, False,  True],\n",
              "        [False, False,  True, False,  True]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that `x.to(torch.bool)` is faster than `x.bool()`, as well as the efficiency.\n",
        "\n",
        "Neat!"
      ],
      "metadata": {
        "id": "Rw89V65i94ku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Information from Tensors\n",
        "\n",
        "Here are the top most common attributes we use:\n",
        "\n",
        "- `shape` - shape of the tensor (some operations require specific shape rules)\n",
        "- `ndim` - number of dimensions\n",
        "- `dtype` - the datatype of the elements in the tensor are stored\n",
        "- `device` - the device the tensor is stored on (usually `cuda` for GPU or `cpu` for Central Processing Unit)"
      ],
      "metadata": {
        "id": "mieIgYg0Lr9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random tensor\n",
        "x = torch.rand(1, 3, 5)\n",
        "\n",
        "print(\"shape:\", x.shape)\n",
        "print(\"dimensions:\", x.ndim)\n",
        "print(\"datatype:\", x.dtype)\n",
        "print(\"device:\", x.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJ9_KBWyMitE",
        "outputId": "6e24e63d-7473-4de8-99c2-d8839a07326a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: torch.Size([1, 3, 5])\n",
            "dimensions: 3\n",
            "datatype: torch.float32\n",
            "device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These common attributes come in handy when it comes to debugging/troubleshooting.\n",
        "\n",
        "When you run into issues in PyTorch, it's very often one to do with one of the three attributes above. So when an error message shows up, ask yourself:\n",
        "\n",
        "- **what** shape are my tensors?\n",
        "- **how** many dimensions are there?\n",
        "- **what** datatype are they?\n",
        "- **where** are they stored, cpu or gpu?"
      ],
      "metadata": {
        "id": "_G7jXLIuNT-O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manipulating Tensors\n",
        "\n",
        "Also known as \"tensor operations,\" these operations are the most important ones:\n",
        "\n",
        "- Addition\n",
        "- Subtraction\n",
        "- Division\n",
        "- Multiplication (element-wise)\n",
        "- Matrix multiplication"
      ],
      "metadata": {
        "id": "wKrFomWaOEfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_a = torch.tensor([1, 2, 3])\n",
        "tensor_b = torch.tensor([4, 5, 6])"
      ],
      "metadata": {
        "id": "7BJq21AUO72_"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic Operations\n",
        "\n",
        "Let's start with the fundamental operations: addition (`+`), subtraction (`-`) and multiplication (`*`, element-wise)."
      ],
      "metadata": {
        "id": "LPAAmciAOgR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Addition (`+`)\n",
        "tensor_a + tensor_b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufoNWzymO1h3",
        "outputId": "414453b5-cd76-462e-8ce0-87f8cbb9da2b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 7, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This results in a new tensor (`[5, 7, 9]`).\n",
        "\n",
        "```python\n",
        "tensor([1, 2, 3])\n",
        "tensor([4, 5, 6])\n",
        "-------------------\n",
        "tensor([5, 7, 9])\n",
        "```\n",
        "\n",
        "You can also use `torch.add(a, b)` to perform this action, it returns the same result."
      ],
      "metadata": {
        "id": "pEpxvSrHPNmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use torch.add()\n",
        "torch.add(tensor_a, tensor_b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8yEW7xUPLQA",
        "outputId": "c280c149-5761-4233-c304-b92412da526b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 7, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Subtraction (`-`)\n",
        "tensor_a - tensor_b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woktJowxQEtr",
        "outputId": "a9fd68f2-a617-4d53-f496-afe694c39a50"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-3, -3, -3])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use torch.subtract()\n",
        "torch.subtract(tensor_a, tensor_b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9N723gO5QJ68",
        "outputId": "8c8338ce-2d26-4ba5-d49f-fe068a698002"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-3, -3, -3])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Multiplication\n",
        "tensor_a * tensor_b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJpwTxb-QSZ9",
        "outputId": "79e61aed-1ef3-4114-8717-0bffc5324ba2"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 4, 10, 18])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use torch.multiply() or torch.mul(), they're aliases\n",
        "torch.multiply(tensor_a, tensor_b), torch.mul(tensor_a, tensor_b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUTIXXsCQcBM",
        "outputId": "64bbaa23-7234-464d-eafc-45ee4da19fad"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 4, 10, 18]), tensor([ 4, 10, 18]))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Division\n",
        "\n",
        "[learnpytorch.io](https://learnpytorch.io) did not mention this, but we'll cover it anyway."
      ],
      "metadata": {
        "id": "fwevaVhOQyUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_a / tensor_b"
      ],
      "metadata": {
        "id": "E42g5dFHQqYW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a01509df-6bcb-4c00-c73e-bb15d409392f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2500, 0.4000, 0.5000])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use torch.divide() to divide tensor_a by tensor_b\n",
        "torch.divide(tensor_a, tensor_b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EL-hVJ4URy2D",
        "outputId": "b083f57e-b3e9-474d-85d2-52c89b5de0bb"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2500, 0.4000, 0.5000])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All these basic operations we saw above ($+$, $-$, $*$ , $\\div$) are all element-wise operations, which is quite simple.\n",
        "\n",
        "Now onto something different üòè."
      ],
      "metadata": {
        "id": "SDnnWmKQSHUq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matrix Multiplication\n",
        "\n",
        "One of the most common operations in machine learning and deep learning algorithms (like neural networks) is matrix multiplication.\n",
        "\n",
        "The main two rules of matrix multiplication are:\n",
        "\n",
        "1. The **inner dimensions** must match (the following are shapes):\n",
        "   - ‚ùå `(1, 2) @ (3, 4)` - Inner dimension does not match (`2 != 3`)\n",
        "   - ‚ùå `(2, 3) @ (2, 3)` - Inner dimension does not match (`3 != 2`)\n",
        "   - ‚úÖ `(2, 3) @ (3, 2)` - Inner dimension matches (`3 == 3`)\n",
        "2. The resulting matrix has the shape of the **outer dimensions**:\n",
        "   - `(2, 3) @ (3, 2)` ‚Üí `(2, 2)`\n",
        "   - `(6, 9) @ (9, 6)` ‚Üí `(6, 6)`\n",
        "\n",
        "> **Note**\n",
        ">\n",
        "> `@` in Python is the syntax of matrix multiplication.\n",
        "\n",
        "<br /><hr /><br />\n",
        "\n",
        "But why those two rules? Let's go through them one by one.\n",
        "\n",
        "Let's first create two matricies:\n",
        "\n",
        "```python\n",
        "tensor([\n",
        "  [1, 2, 3],\n",
        "  [4, 5, 6]\n",
        "])\n",
        "shape: torch.Size([2, 3])\n",
        "\n",
        "tensor([\n",
        "  [1, 2],\n",
        "  [3, 4],\n",
        "  [5, 6]\n",
        "])\n",
        "shape: torch.Size([3, 2])\n",
        "```\n",
        "\n",
        "<br />\n",
        "\n",
        "Let's take a look at the visualization of this matrix multiplication `(2, 3) @ (3, 2)`:\n",
        "\n",
        "<img alt=\"Matrix Multiplication Visualized\"\n",
        "  src=\"https://github.com/AWeirdScratcher/models/assets/90096971/e0c710ef-cafa-4b8f-a70f-5ba9f27c7ab5\" width=\"740\" />\n",
        "\n",
        "We get:\n",
        "\n",
        "```python\n",
        "tensor([[22, 28], [49, 64]])\n",
        "```\n",
        "\n",
        "Matrix multiplication, unlike the *element-wise* multiplication from basic operations we saw earlier (which multiplies `a` by `b` element-by-element), involves \"flipping\" matricies as you saw from the visualization image.\n",
        "\n",
        "Let's achieve this in code with PyTorch.\n",
        "\n",
        "> **Note**\n",
        ">\n",
        "> The result (`tensor([[22, 28], [49, 64]])`) is also referred to as the *dot product* of the two matricies.\n"
      ],
      "metadata": {
        "id": "7oUcyAChR9Ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tensor A and B\n",
        "tensor_a = torch.tensor([\n",
        "  [1, 2, 3],\n",
        "  [4, 5, 6]\n",
        "])\n",
        "tensor_b = torch.tensor([\n",
        "  [1, 2],\n",
        "  [3, 4],\n",
        "  [5, 6]\n",
        "])"
      ],
      "metadata": {
        "id": "j9iTV_koZW7N"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = tensor_a @ tensor_b\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaGwNKPfW_I7",
        "outputId": "d86b94d9-567a-44e7-dff9-b9632b39942c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[22, 28],\n",
              "        [49, 64]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now try `torch.matmul` or `torch.mm`:"
      ],
      "metadata": {
        "id": "NZ-1oUry5iGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_matmul = torch.matmul(tensor_a, tensor_b)\n",
        "result_mm = torch.mm(tensor_a, tensor_b)\n",
        "\n",
        "print(\"matmul:\")\n",
        "print(result_matmul)\n",
        "print(\"mm:\")\n",
        "print(result_mm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZQOmE_V5qmw",
        "outputId": "efadc160-e16e-467e-8216-90ece5de25e4"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matmul:\n",
            "tensor([[22, 28],\n",
            "        [49, 64]])\n",
            "mm:\n",
            "tensor([[22, 28],\n",
            "        [49, 64]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both of them perform matrix multiplication, while the AT (`@`) symbol is shorter, it's not recommended to use this in code."
      ],
      "metadata": {
        "id": "ihYvlFcm6KGX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's check if `tensor_a` and `tensor_b`'s inner dimensions match."
      ],
      "metadata": {
        "id": "gybooKphQjYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a_inner = tensor_a.shape[1] # (2x\"3\")\n",
        "b_inner = tensor_b.shape[0] # (\"3\"x2)\n",
        "\n",
        "a_inner == b_inner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8A1A1bniQsfP",
        "outputId": "0058e379-8567-4f8d-cd2a-0fd44f65b4c6"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "They do match!\n",
        "\n",
        "If we take a look at the shape of the tensor after performing matrix multiplication (named as `result`), it should be a `2x2` because according to **Rule #2**:\n",
        "\n",
        "> **RULE 2**\n",
        ">\n",
        "> The resulting matrix has the shape of the outer dimensions:\n",
        "> - `(2, 3) @ (3, 2)` ‚Üí `(2, 2)`\n",
        "> - `(6, 9) @ (9, 6)` ‚Üí `(6, 6)`\n",
        "\n",
        "So in this case:\n",
        "\n",
        "`(2, 3) @ (3, 2)` ‚Üí `torch.Size([2, 2])`\n",
        "\n",
        "Let's check whether our theory is true or not."
      ],
      "metadata": {
        "id": "aUHU7WTfRE2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"matrix:\")\n",
        "print(result)\n",
        "\n",
        "print(\"shape:\")\n",
        "print(result.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1it6stL573P7",
        "outputId": "b83c0599-c847-4c14-b281-9ff210f4d605"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matrix:\n",
            "tensor([[22, 28],\n",
            "        [49, 64]])\n",
            "shape:\n",
            "torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But what if we have tensors in different shapes? Can we still perform matrix multiplication in this case?"
      ],
      "metadata": {
        "id": "sTepmjIe8HbI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dealing with Shapes\n",
        "\n",
        "One of the most common errors you'll run into in deep learning or when manipulating (operating) tensors is \"shape errors.\"\n",
        "\n",
        "Let's say, we want to do matrix multiplication between `tensor_p` and `tensor_q`, but their shapes are completely the same."
      ],
      "metadata": {
        "id": "CfmYIjMq8RFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_p = torch.tensor([\n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6]\n",
        "])\n",
        "tensor_q = torch.tensor([\n",
        "    [7, 8, 9],\n",
        "    [0, 1, 2]\n",
        "])\n",
        "\n",
        "tensor_p.shape, tensor_q.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Js91of379B28",
        "outputId": "db1f8ffe-3077-4884-80f0-ad2944937909"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 3]), torch.Size([2, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "...they're both a 2x3.\n",
        "\n",
        "We can make the matrix multiplication work between tensor $p$ and $q$ by making their inner dimensions match.\n",
        "\n",
        "One of the ways to do this is with a **transpose** (switch the dimensions of a given tensor).\n",
        "\n",
        "You can perform transposes in PyTorch using either:\n",
        "\n",
        "- `torch.transpose(input, dim0, dim1)` - where `input` is the desired tensor to transpose and `dim0` and `dim1` are the dimensions to be swapped.\n",
        "- `tensor.T` - where `tensor` is the desired tensor to transpose.\n",
        "\n",
        "If we take a look at the two tensors ($p$ and $q$), we need to swap the dimensions from one of them.\n",
        "\n",
        "We'll take `tensor_p` as an example.\n"
      ],
      "metadata": {
        "id": "JRbsW7-f9OZj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### torch.transpose\n",
        "\n",
        "Since our shape is `torch.Size([2, 3])`, it means our first (index `0`) dimension has two items, and the second (index `1`) one has three elements.\n",
        "\n",
        "We can swap its dimensions using `torch.transpose()`."
      ],
      "metadata": {
        "id": "wTlSpd0YRwIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transposed_p = torch.transpose(\n",
        "    input=tensor_p,\n",
        "    dim0=0, # first dimension\n",
        "    dim1=1  # second dimension\n",
        ")\n",
        "transposed_p, transposed_p.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROGhHinq9vbv",
        "outputId": "7cb8b272-d4bf-44c3-cba5-d8a0553c9626"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1, 4],\n",
              "         [2, 5],\n",
              "         [3, 6]]),\n",
              " torch.Size([3, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_p, tensor_p.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA6odNfo-C2c",
        "outputId": "f81544d0-d855-490c-a6a3-cd535e3353b9"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1, 2, 3],\n",
              "         [4, 5, 6]]),\n",
              " torch.Size([2, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now you can do matrix multiplication w/out errors\n",
        "transposed_p @ tensor_q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwUirtm9VYYo",
        "outputId": "8debecc8-38ab-444f-918a-abdc8179e9ba"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7, 12, 17],\n",
              "        [14, 21, 28],\n",
              "        [21, 30, 39]])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparing the transposed tensor with the original one, we can clearly see it has been sort of \"flipped,\" as well as its shape.\n",
        "\n",
        "Now we can do matrix multiplication between the transposed $p$ tensor (`3x2`) and the $q$ tensor (`2x3`) since their inner dimensions match.\n",
        "\n",
        "<details>\n",
        "  <summary>tensor.transpose</summary>\n",
        "  <p>\n",
        "\n",
        "You can also use `tensor.transpose()`.\n",
        "\n",
        "```python\n",
        "tensor_p.transpose(0, 1)\n",
        "```\n",
        "\n",
        "  </p>\n",
        "</details>"
      ],
      "metadata": {
        "id": "rAmcdyoE-4UM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### tensor.T, tensor.mT\n",
        "\n",
        "There's also a simpler approach: `tensor.T`.\n",
        "\n",
        "> **[tensor.T](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.T)**\n",
        ">\n",
        "> Returns a view of this tensor with its dimensions reversed."
      ],
      "metadata": {
        "id": "B-09hiy3RmVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transposed_p = tensor_p.T # tensor.T\n",
        "transposed_p, transposed_p.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDPNvXpR_jNc",
        "outputId": "dd4cc009-007b-4356-d245-0c30ec4dbe4c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1, 4],\n",
              "         [2, 5],\n",
              "         [3, 6]]),\n",
              " torch.Size([3, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now do matrix multiplication\n",
        "transposed_p @ tensor_q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uc7pnBfDVgfV",
        "outputId": "2d872ec2-89ca-424c-db28-f79375108e34"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7, 12, 17],\n",
              "        [14, 21, 28],\n",
              "        [21, 30, 39]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sidenote, you can transpose the last two dimensions with `tensor.mT`.\n",
        "\n",
        "> **[tensor.mT](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.mT)**\n",
        ">\n",
        "> Returns a view of this tensor with the last two dimensions transposed.\n",
        "> `x.mT` is equivalent to `x.transpose(-2, -1)`."
      ],
      "metadata": {
        "id": "2BO0du04_qsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_3d = torch.rand(2, 3, 4)\n",
        "tensor_3d.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfkpND1OAvOu",
        "outputId": "9fff3417-b286-4569-d68f-30ce07aa84c3"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_3d.mT.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOVUaTVmBBk6",
        "outputId": "d62accb9-af12-40ec-fa4e-38a48c46111b"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### torch.permute\n",
        "\n",
        "`tensor.mT` only transposes the last two dimensions. If you want to completely reverse the tensor's (`tensor_3d`) dimensions, use `torch.permute()` to permute (rearrange) its dimensions.\n",
        "\n",
        "> <sub><b><a href=\"https://pytorch.org/docs/stable/generated/torch.permute.html#torch-permute\" target=\"_blank\">TORCH.PERMUTE</a></b></sub>\n",
        ">\n",
        "> `torch.permute(input, dims)` ‚Üí [Tensor](https://pytorch.org/docs/stable/tensors.html#torch.Tensor)\n",
        ">\n",
        "> Returns a view of the original tensor input with its dimensions permuted.\n",
        ">\n",
        "> - input (<a href=\"https://pytorch.org/docs/stable/tensors.html#torch.Tensor\" target=\"_blank\"><i>Tensor</i></a>) - the input tensor.\n",
        "> - dims (<i>tuple of int</i>) - The desired ordering of dimensions.\n",
        "\n",
        "Since there are 3 dimensions, the original indices are:\n",
        "\n",
        "- dimension 1 (index `0`)\n",
        "- dimension 2 (index `1`)\n",
        "- dimension 3 (index `2`)\n",
        "\n",
        "How do we swap the dimensions thoroughly? You've guessed it! Just flip the dimension indicies around:\n",
        "\n",
        "- **new** dimension 1 (feed dimension 3, index `2`)\n",
        "- **new** dimension 2 (feed dimension 2, index `1`)\n",
        "- **new** dimension 3 (feed dimension 1, index `0`)"
      ],
      "metadata": {
        "id": "oE9Z9B84BUkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"original shape:\", tensor_3d.shape)\n",
        "print(\"permuted shape:\", torch.permute(tensor_3d, (2, 1, 0)).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAd767JQDhZr",
        "outputId": "377a2a1c-be9a-4986-9e88-8b200e8dfd64"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original shape: torch.Size([2, 3, 4])\n",
            "permuted shape: torch.Size([4, 3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Working as expected! But we have a lot more than just three dimensions?\n",
        "\n",
        "Let's say, we have 5 dimensions, then the code above (`(2, 1, 0)`) would raise an error."
      ],
      "metadata": {
        "id": "9iVyTM83FVxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_5d = torch.rand(1, 2, 3, 4, 5)\n",
        "\n",
        "try:\n",
        "  torch.permute(tensor_5d, (2, 1, 0))\n",
        "except RuntimeError as error:\n",
        "  # fancy\n",
        "  display(\n",
        "      HTML(\"\"\"\\\n",
        "      <p style=\"font-family: monospace\">\n",
        "        <span style=\"color: red\">RuntimeError</span>: {}\n",
        "      </p>\"\"\".format(error))\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "CNSPwa2rFYIg",
        "outputId": "d92a8e0a-900e-4ee1-b1d9-90faea48a156"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "      <p style=\"font-family: monospace\">\n",
              "        <span style=\"color: red\">RuntimeError</span>: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 5 is not equal to len(dims) = 3\n",
              "      </p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To fix this, we can use [`torch.arange`](#scrollTo=Range) to create a range numbers, starting from the $n$ (number of dimensions) to 0, and convert it into a list.\n",
        "\n",
        "It generates an Arithmetic sequence like the following, with the common difference as $-1$ and the last item as $0$.\n",
        "\n",
        "$$\n",
        "n-1,\\ n-2,\\ n-3,\\ \\cdots,\\ 0\\\\\n",
        "% leave a space after a backslash to create spacing\n",
        "$$\n",
        "\n",
        "> **Note**\n",
        ">\n",
        "> $n = 5$, which is the number of dimensions (`ndim`) the five-dimensional tensor (`tensor_5d`) has."
      ],
      "metadata": {
        "id": "9NcO2en0F2xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reversed_indices = (\n",
        "    torch.arange((tensor_5d.ndim - 1), -1, step=-1) # n-1, n-2, n-3, ..., 0\n",
        "    .tolist() # convert to list\n",
        ")\n",
        "reversed_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0yhtySQH_kS",
        "outputId": "47c50049-d060-42cd-eaaa-b2be5e4d9490"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4, 3, 2, 1, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first start from $n-1$ (index of the last dimension) to `0` (index of the first dimension). The step is `-1` to ensure we're going backwards, in order to fully reverse the tensor's dimensions.\n",
        "\n",
        "Next, pass the value to the argument `dims`."
      ],
      "metadata": {
        "id": "c7ukWT8RIP3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"original shape:\", tensor_5d.shape)\n",
        "print(\"permuted shape:\", torch.permute(tensor_5d, reversed_indices).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQJYXDwDI3xz",
        "outputId": "fe48c41f-e274-4aa2-f0d1-9273fe6a8340"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original shape: torch.Size([1, 2, 3, 4, 5])\n",
            "permuted shape: torch.Size([5, 4, 3, 2, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "  <summary>tensor.permute</summary>\n",
        "  <p>\n",
        "\n",
        "You can also use `tensor.permute()`.\n",
        "\n",
        "```python\n",
        "tensor_5d.permute(*reversed_indices)\n",
        "```\n",
        "\n",
        "  </p>\n",
        "</details>\n",
        "\n",
        "Note that the `torch.permute` description above in this section is not from [learnpytorch.io](https://learnpytorch.io), but rather the PyTorch documentation."
      ],
      "metadata": {
        "id": "Vz5xBa2cKKrX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reshaping Tensors\n",
        "\n",
        "In this section, we'll talk about reshaping tensors with `tensor.reshape()` and `tensor.view()`.\n"
      ],
      "metadata": {
        "id": "izHtaIU0TS10"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### tensor.reshape\n",
        "\n",
        "As the name suggests, `tensor.reshape(input, shape)` just returns a reshaped version of the input with a given shape.\n",
        "\n",
        "This is slightly different from `tensor.permute()`, which is used for rearranging the dimensions.\n",
        "\n",
        "First, let's create a grid of ones."
      ],
      "metadata": {
        "id": "vIvb1tDQY5BG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a bunch of ones\n",
        "ones = torch.ones(4, 3)\n",
        "ones"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgFL8AHBXOfd",
        "outputId": "c3d945a6-27f4-4a9d-f566-b7e07c524710"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape to a vector\n",
        "ones.reshape(12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lbb3bjZrXQ_4",
        "outputId": "fd707f26-3dc8-4f91-ee3e-7dafd63116c8"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape to another matrix\n",
        "ones.reshape(2, 6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJi2vQKOXTAU",
        "outputId": "b43db630-a283-4565-cb5b-806ce154968f"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### tensor.view\n",
        "\n",
        "`tensor.view()` is also a way of reshaping tensors, but it's still slightly different from `tensor.reshape`, and we'll talk about this later."
      ],
      "metadata": {
        "id": "J-lrfBJpY9pQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a bunch of zeros\n",
        "zeros = torch.zeros(4, 3)\n",
        "zeros"
      ],
      "metadata": {
        "id": "eYglCAuKXnaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4904f3c3-116b-404e-d372-0dc3d27a3fbd"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zeros.view(12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XAifGZbbOFk",
        "outputId": "b996fb3c-e216-4ca6-c211-18205a22fef8"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zeros.view(2, 6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8kPqrS-bYX4",
        "outputId": "25a8a3fb-b2dd-4738-ce33-89f7811bb3e3"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is quite similar to `tensor.reshape()`, but there's still a slight difference."
      ],
      "metadata": {
        "id": "2kXU1a_AbUz3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comparison\n",
        "\n",
        "On the documentation of `torch.reshape()` and a [StackOverflow answer](https://stackoverflow.com/a/49644300):\n",
        "\n",
        "> <sub><b><a href=\"https://pytorch.org/docs/master/generated/torch.reshape.html#torch-reshape\" target=\"_blank\">TORCH.RESHAPE</a></b></sub>\n",
        ">\n",
        "> `torch.reshape(input, shape)` ‚Üí [Tensor](https://pytorch.org/docs/master/tensors.html#torch.Tensor)\n",
        ">\n",
        "> Returns a tensor with the same data and number of elements as input, but with the specified shape. **When possible, the returned tensor will be a view of input. Otherwise, it will be a copy.** Contiguous inputs and inputs with compatible strides can be reshaped without copying, but you should not depend on the copying vs. viewing behavior.\n",
        "\n",
        "It means that `torch.reshape()` may return **a copy** or **a view** of the original tensor. You cannot count on that to return a view or a copy. According to the developer:\n",
        "\n",
        "> If you need a copy, use `clone()`; if you need the same storage, use `view()`. The semantics of `reshape()` are that **it may or may not share the storage and you don't know beforehand.**\n",
        "\n",
        "In conclusion, `reshape()` may or may not create a copy you don't know beforehand. So if you'd like to create a copy, just use `copy()`.\n",
        "\n",
        "According to [learnpytorch.io](https://learnpytorch.io):\n",
        "\n",
        "> ```python\n",
        "> # Change view (keeps same data as original but changes view)\n",
        "> # See more: https://stackoverflow.com/a/54507446/7900723\n",
        "> z = x.view(1, 7)\n",
        "> z, z.shape\n",
        "> ```\n",
        ">\n",
        "> Remember though, changing the view of a tensor with `torch.view()` really only creates a new view of the same tensor.\n",
        ">\n",
        "> So changing the view changes the original tensor too.\n",
        "\n",
        "I personally would recommend using `tensor.view()` if you want to share the same storage and `tensor.clone().view()` if not. Just never use `tensor.reshape()` to prevent unexpected results to happen."
      ],
      "metadata": {
        "id": "TxEnKOxqdmGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random tensor\n",
        "x = torch.rand(4, 3)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWQkzYqCkC5N",
        "outputId": "90b34523-e23f-4f12-da02-e4bd1bf7a0f6"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3514, 0.8087, 0.3396],\n",
              "        [0.1332, 0.4118, 0.2576],\n",
              "        [0.3470, 0.0240, 0.7797],\n",
              "        [0.1519, 0.7513, 0.7269]])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a view\n",
        "x_view = x.view(2, 6)\n",
        "x_view"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztG8hXI0kHgb",
        "outputId": "60e74ca9-15fd-451f-ed73-5f8cb92dcc64"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3514, 0.8087, 0.3396, 0.1332, 0.4118, 0.2576],\n",
              "        [0.3470, 0.0240, 0.7797, 0.1519, 0.7513, 0.7269]])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a clone (copy) and then reshape it\n",
        "x_copy = x.clone().view(2, 6)\n",
        "x_copy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh363Q49kZ-W",
        "outputId": "371cb4ea-6820-4be3-911a-80b655f689b1"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3514, 0.8087, 0.3396, 0.1332, 0.4118, 0.2576],\n",
              "        [0.3470, 0.0240, 0.7797, 0.1519, 0.7513, 0.7269]])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown You don't need to understand what this code means.\n",
        "# @markdown [PyTorch Discussion](https://discuss.pytorch.org/t/any-way-to-check-if-two-tensors-have-the-same-base/44310/2)\n",
        "\n",
        "# Check their address\n",
        "x_pointer = x.data_ptr()\n",
        "xv_pointer = x_view.data_ptr()\n",
        "xc_pointer = x_copy.data_ptr()\n",
        "\n",
        "# Check if they're in the same storage as x\n",
        "print(\"x & x_view share the same storage?\", x_pointer == xv_pointer)\n",
        "print(\"x & x_copy share the same storage?\", x_pointer == xc_pointer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kdURJ1vk8PW",
        "outputId": "94832f16-6ff7-43c3-8be4-7f458f7d99bf"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x & x_view share the same storage? True\n",
            "x & x_copy share the same storage? False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apparently, they do not store in the same storage. Now let's try changing the value of `x` and see if it affects `x_view` and `x_copy`."
      ],
      "metadata": {
        "id": "0upYYpkPl2cO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the value of x affects x_view, too\n",
        "x.fill_(69)\n",
        "print(\"x:\")\n",
        "print(x)\n",
        "\n",
        "print(\"\\nx_view:\")\n",
        "print(x_view)\n",
        "print(\"\\nx_copy:\")\n",
        "print(x_copy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MzUlAiFkPrU",
        "outputId": "24bba909-b72f-449a-b7d6-2536d4263e81"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x:\n",
            "tensor([[69., 69., 69.],\n",
            "        [69., 69., 69.],\n",
            "        [69., 69., 69.],\n",
            "        [69., 69., 69.]])\n",
            "\n",
            "x_view:\n",
            "tensor([[69., 69., 69., 69., 69., 69.],\n",
            "        [69., 69., 69., 69., 69., 69.]])\n",
            "\n",
            "x_copy:\n",
            "tensor([[0.3514, 0.8087, 0.3396, 0.1332, 0.4118, 0.2576],\n",
            "        [0.3470, 0.0240, 0.7797, 0.1519, 0.7513, 0.7269]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`x_copy` stays in its place and did not get affected by the changes of `x` at all.\n",
        "\n",
        "In conclusion, `x.view()` is kind of like saying, \"I want to view the original tensor this way, but don't change it,\" while `x.clone().view()` is like saying \"give me a complete copy of it and view it this way so I won't mistakenly change the original tensor.\"\n",
        "\n",
        "**TLDR;** `tensor.reshape()` is not recommended."
      ],
      "metadata": {
        "id": "g6rQ7gV-nO5a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### torch.stack\n",
        "\n",
        "You can stack tensors on top of each other with `torch.stack(tensors, dim=0)`."
      ],
      "metadata": {
        "id": "PY4qMSMIn5Ox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a vector\n",
        "x = torch.arange(0, 51, step=5)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Aoj5pyKoxmi",
        "outputId": "252c778d-0d16-4152-c984-d38194df3b8e"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  5, 10, 15, 20, 25, 30, 35, 40, 45, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.stack([x, x, x])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ud-_uQho48D",
        "outputId": "e9ddcb0e-e374-4e80-b10d-1c38dfa9297d"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  5, 10, 15, 20, 25, 30, 35, 40, 45, 50],\n",
              "        [ 0,  5, 10, 15, 20, 25, 30, 35, 40, 45, 50],\n",
              "        [ 0,  5, 10, 15, 20, 25, 30, 35, 40, 45, 50]])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also specify its dimension to insert."
      ],
      "metadata": {
        "id": "4XCgtjSspKY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor with three dimensions\n",
        "Q = torch.rand(1, 2, 3)\n",
        "Q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hvgsXySpRRf",
        "outputId": "0bbeb706-16c7-4d24-82e8-5c817c3ce089"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.8572, 0.1165, 0.8596],\n",
              "         [0.2636, 0.6855, 0.9696]]])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack them along the second dimension (index `1`)\n",
        "torch.stack([Q, Q], dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlvVUMa_pXC6",
        "outputId": "0917280d-1e2d-4f76-d954-3a14cee71cd5"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.8572, 0.1165, 0.8596],\n",
              "          [0.2636, 0.6855, 0.9696]],\n",
              "\n",
              "         [[0.8572, 0.1165, 0.8596],\n",
              "          [0.2636, 0.6855, 0.9696]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### torch.squeeze\n",
        "\n",
        "Squeezes input to remove all the dimenions with value 1.\n",
        "\n",
        "> Returns a tensor with all specified dimensions of input of size 1 removed.\n",
        ">\n",
        "> (Documentation)"
      ],
      "metadata": {
        "id": "K-ymPRfZqB8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random tensor with shape (1, 2, 1, 2)\n",
        "x = torch.rand(1, 2, 1, 2)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZxBybZ1qvfH",
        "outputId": "d394e179-7469-4817-9b1f-6e1d0486f043"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_sq = x.squeeze()\n",
        "x_sq.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0GrYBWorMle",
        "outputId": "8e5e5150-eae7-4a04-de35-ac3ee00e4b2e"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove dimension #3 (index 2)\n",
        "# It will be squeezed because it only has one element (size is 1).\n",
        "x.squeeze(2).shape"
      ],
      "metadata": {
        "id": "aARS_kZDsOCg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c07ddea1-bd32-4188-e5ed-335d953836e0"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### torch.unsqueeze\n",
        "\n",
        "This is the oppisite of `torch.squeeze()`. This function inserts a dimension value of `1` at a specific (dimension) index."
      ],
      "metadata": {
        "id": "4Ipyrsfl4zGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random 2x3 matrix\n",
        "a = torch.rand(2, 3)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioCJrnAK6zGn",
        "outputId": "dd6eb894-7c01-42a6-ea1f-cb86b966a22f"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7400, 0.0036, 0.8104],\n",
              "        [0.8741, 0.9729, 0.3821]])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# At the first dimension (index 0), insert a dimension value of 1.\n",
        "torch.unsqueeze(a, dim=0).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT4gOG09-GJT",
        "outputId": "33c25b53-90ba-49e7-c06c-fa0b4ead9050"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# At the second dimension (index 1), insert a dimension value of 1.\n",
        "torch.unsqueeze(a, dim=1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQewTOdS-OS8",
        "outputId": "f5c0f8ca-cd52-405e-f163-4360817e5877"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is kind of like doing `list.insert(pos)` in Python.\n",
        "\n",
        "```python\n",
        "shape = [2, 3]\n",
        "shape.insert(1, 1) # at pos 1, insert a 1\n",
        "print(shape)\n",
        "```\n",
        "\n",
        "You can think of `torch.squeeze()` as making your tensor a bit tighter, and `torch.unsqueeze()` as loosening your tensor."
      ],
      "metadata": {
        "id": "iusOb-GP-hCB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Indexing\n",
        "\n",
        "Given a list like this:\n",
        "\n",
        "```python\n",
        "In [1]: list_ = [\"chocolate\", \"pytorch\", \"apple\", \"banana\"]\n",
        "```\n",
        "\n",
        "If I want to get the text `\"pytorch\"` from the list (`list_`), I can use list indexing, which involves a little bit of \"square bracket magic.\"\n",
        "\n",
        "```python\n",
        "In [2]: list_[1] # second item (\"pytorch\")\n",
        "Out[2]: 'pytorch'\n",
        "```\n",
        "\n",
        "The same approach applies to PyTorch tensors."
      ],
      "metadata": {
        "id": "v1NyxO22BBmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a vector\n",
        "vector = torch.arange(1, 11, dtype=torch.float)\n",
        "vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kcy1iwX7J2Zf",
        "outputId": "926daab4-2424-43f8-afe3-487d789e6239"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the 7.0\n",
        "vector[6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n65HRZ2fKAVl",
        "outputId": "2a718309-deaf-44a6-9c6f-312c1a8a85e3"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, if we have a matrix (grid) like 3x5, how do you get the exact item you're looking for, say, the first column in the second row?\n",
        "\n",
        "You can think of matricies (grids) as lists that contain sub-lists:\n",
        "\n",
        "```python\n",
        "matrix = [\n",
        "  [1, 9, 8, 9],\n",
        "  [0, 6, 0, 4]\n",
        "]\n",
        "```\n",
        "\n",
        "To get the number \"8,\" which is located at the second column in the first row:\n",
        "\n",
        "```python\n",
        "eight = matrix[0][2]\n",
        "# => 8\n",
        "```\n",
        "\n",
        "Again, the same approach applies to PyTorch tensors."
      ],
      "metadata": {
        "id": "WOp_YALIKJei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a matrix\n",
        "MATRIX = torch.arange(0, 100).view(4, 25)\n",
        "MATRIX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qsj1f9C7LBeh",
        "outputId": "2eaa197b-90f6-43eb-90af-a8648ca5a6e9"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "         18, 19, 20, 21, 22, 23, 24],\n",
              "        [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42,\n",
              "         43, 44, 45, 46, 47, 48, 49],\n",
              "        [50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
              "         68, 69, 70, 71, 72, 73, 74],\n",
              "        [75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92,\n",
              "         93, 94, 95, 96, 97, 98, 99]])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number 25 (a scalar)\n",
        "MATRIX[1][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTqQ-HUHLV_x",
        "outputId": "68617f45-2dc9-4c2f-f9e7-6d6a6e211b5b"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(25)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use `[1, 0]` in PyTorch (but not vanilla Python)."
      ],
      "metadata": {
        "id": "ynHX6vAlLwS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX[1, 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUJZyjz-L2Ng",
        "outputId": "b2ab0019-d560-482b-d30f-b16aa32ca4eb"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(25)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also use `:` (a colon, or [slice](https://docs.python.org/3/glossary.html#term-slice) in Python) followed by a comma and the desired index to specify \"all values in this column\""
      ],
      "metadata": {
        "id": "cDZuk7diMLPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the items in the first column\n",
        "MATRIX[:, 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CAlRXgnMU2H",
        "outputId": "17d54f66-7a56-48f1-c33f-cceea134e665"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0, 25, 50, 75])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's visualize `MATRIX[:, 0]`:\n",
        "\n",
        "<img alt=\"matrix-column-0 visualization\" src=\"https://github.com/AWeirdScratcher/models/assets/90096971/b58ddd92-936f-4f2a-833e-f5242d22d961\" width=\"740\" />\n",
        "\n",
        "And that's why it returns `tensor([0, 25, 50, 75])`.\n",
        "\n",
        "With the same approach, what do you think `MATRIX[:, 2]` would return?"
      ],
      "metadata": {
        "id": "l1ZgP7ZrQvhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX[:, 2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaWftIDBQvK1",
        "outputId": "420cc200-900d-42b9-fb3b-f0d5bc4c4098"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2, 27, 52, 77])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's also try a three-dimensional tensor."
      ],
      "metadata": {
        "id": "W9JmIokjRwui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR = torch.arange(1, 11).view(1, 2, 5)\n",
        "TENSOR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3ccsCryR3j5",
        "outputId": "5b901a40-34eb-4abb-bab4-1ba4a74f3e6d"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1,  2,  3,  4,  5],\n",
              "         [ 6,  7,  8,  9, 10]]])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the first number\n",
        "TENSOR[0, 0, 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvFmktxPURMr",
        "outputId": "f8920d33-b512-4b52-979a-5298209b8e17"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    }
  ]
}